{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('AGG')\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import (Input, Activation, Conv3D, Dense, Dropout, Flatten,\n",
    "                          MaxPooling3D, Input, average)\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All hyperparameter and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 32\n",
    "epoch = 10\n",
    "\n",
    "videos = '/content/drive/My Drive/KTH_dataset'\n",
    "nclass = 6\n",
    "output ='/content/drive/My Drive/activity_output'\n",
    "\n",
    "color = False\n",
    "skip = True\n",
    "depth = 32\n",
    "nmodel = 2\n",
    "\n",
    "if not os.path.isdir(output):\n",
    "    os.makedirs(output)\n",
    "\n",
    "img_rows, img_cols, frames=120, 120, depth\n",
    "channel=3 if color else 1\n",
    "\n",
    "nb_classes = nclass\n",
    "countlis = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading pickle Data from local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(598, 32, 120, 120)\n",
      "(598, 6)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('Dataset_activity/data', 'rb') as f:\n",
    "    Xin = pickle.load(f)\n",
    "print(Xin.shape)\n",
    "with open('Dataset_activity/label', 'rb') as f:\n",
    "    Yin = pickle.load(f)\n",
    "print(Yin.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 32, 120, 120) (418, 6)\n",
      "(180, 32, 120, 120) (180, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(Xin, Yin, test_size=0.3, random_state=4)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding data to a 5th axis for compatibity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 32, 120, 120, 1) (180, 32, 120, 120, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.expand_dims(X_train,4)\n",
    "X_test = np.expand_dims(X_test,4)\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating sequential Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3dcnn(shape, nb_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(16, kernel_size=(11,11,32), activation='relu', kernel_regularizer=l2(0.01),input_shape=(shape),padding=\"same\"))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "    #model.add(Dropout(0.25))\n",
    "    #print(\"coming\",input_shape)\n",
    "\n",
    "    model.add(Conv3D(16, kernel_size=(5,5,32),activation='relu',kernel_regularizer=l2(0.01),padding=\"same\"))\n",
    "    #model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "    \n",
    "    \n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(6400, activation='sigmoid'))\n",
    "    #model.add(Dropout(0.25))\n",
    "    model.add(Dense(nb_classes, activation='softmax', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 32, 120, 120, 16]\n",
      "[None, 32, 120, 120, 16]\n",
      "[None, 16, 60, 60, 16]\n",
      "[None, 16, 60, 60, 16]\n",
      "[None, 8, 30, 30, 16]\n",
      "[None, None]\n",
      "[None, 6]\n"
     ]
    }
   ],
   "source": [
    "shape = (32,120,120,1)  # creating shape compatible with \n",
    "model = create_3dcnn((shape), nb_classes)\n",
    "for layer in model.layers:\n",
    "    print(layer.get_output_at(0).get_shape().as_list())\n",
    "early_stopping = EarlyStopping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Summary of the Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 32, 120, 120, 16)  61968     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 16, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 16, 60, 60, 16)    204816    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 8, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 115200)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 691206    \n",
      "=================================================================\n",
      "Total params: 957,990\n",
      "Trainable params: 957,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr=0.0001) #change learning rates according to user need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model0:\n",
      "Train on 418 samples, validate on 180 samples\n",
      "Epoch 1/800\n",
      "418/418 [==============================] - 208s 498ms/step - loss: 2.2319 - accuracy: 0.1603 - val_loss: 2.3315 - val_accuracy: 0.1722\n",
      "Epoch 2/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.1341 - accuracy: 0.1651 - val_loss: 2.1435 - val_accuracy: 0.1444\n",
      "Epoch 3/800\n",
      "418/418 [==============================] - 162s 387ms/step - loss: 2.1083 - accuracy: 0.1388 - val_loss: 2.1032 - val_accuracy: 0.1556\n",
      "Epoch 4/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0945 - accuracy: 0.1722 - val_loss: 2.1002 - val_accuracy: 0.1722\n",
      "Epoch 5/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0961 - accuracy: 0.1699 - val_loss: 2.0949 - val_accuracy: 0.1722\n",
      "Epoch 6/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0922 - accuracy: 0.1507 - val_loss: 2.1005 - val_accuracy: 0.1500\n",
      "Epoch 7/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0906 - accuracy: 0.2010 - val_loss: 2.0898 - val_accuracy: 0.1500\n",
      "Epoch 8/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0902 - accuracy: 0.1555 - val_loss: 2.0850 - val_accuracy: 0.1778\n",
      "Epoch 9/800\n",
      "418/418 [==============================] - 162s 389ms/step - loss: 2.0936 - accuracy: 0.1196 - val_loss: 2.0888 - val_accuracy: 0.1556\n",
      "Epoch 10/800\n",
      "418/418 [==============================] - 162s 389ms/step - loss: 2.0915 - accuracy: 0.1627 - val_loss: 2.0831 - val_accuracy: 0.1722\n",
      "Epoch 11/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0880 - accuracy: 0.1770 - val_loss: 2.0784 - val_accuracy: 0.2556\n",
      "Epoch 12/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0858 - accuracy: 0.1890 - val_loss: 2.0848 - val_accuracy: 0.1500\n",
      "Epoch 13/800\n",
      "418/418 [==============================] - 162s 389ms/step - loss: 2.0858 - accuracy: 0.1914 - val_loss: 2.0853 - val_accuracy: 0.1778\n",
      "Epoch 14/800\n",
      "418/418 [==============================] - 162s 389ms/step - loss: 2.0885 - accuracy: 0.1770 - val_loss: 2.0957 - val_accuracy: 0.1611\n",
      "Epoch 15/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0888 - accuracy: 0.1914 - val_loss: 2.0813 - val_accuracy: 0.1778\n",
      "Epoch 16/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0853 - accuracy: 0.1770 - val_loss: 2.0814 - val_accuracy: 0.1722\n",
      "Epoch 17/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0819 - accuracy: 0.1818 - val_loss: 2.0778 - val_accuracy: 0.2722\n",
      "Epoch 18/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 2.0839 - accuracy: 0.2129 - val_loss: 2.0777 - val_accuracy: 0.1778\n",
      "Epoch 19/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 2.0839 - accuracy: 0.1746 - val_loss: 2.0777 - val_accuracy: 0.1833\n",
      "Epoch 20/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 2.0820 - accuracy: 0.1842 - val_loss: 2.0916 - val_accuracy: 0.1500\n",
      "Epoch 21/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 2.0787 - accuracy: 0.2153 - val_loss: 2.0833 - val_accuracy: 0.1500\n",
      "Epoch 22/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 2.0831 - accuracy: 0.1842 - val_loss: 2.0835 - val_accuracy: 0.1556\n",
      "Epoch 23/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 2.0765 - accuracy: 0.1746 - val_loss: 2.0708 - val_accuracy: 0.3333\n",
      "Epoch 24/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 2.0725 - accuracy: 0.2512 - val_loss: 2.0820 - val_accuracy: 0.1500\n",
      "Epoch 25/800\n",
      "418/418 [==============================] - 162s 389ms/step - loss: 2.0785 - accuracy: 0.1794 - val_loss: 2.0865 - val_accuracy: 0.1778\n",
      "Epoch 26/800\n",
      "418/418 [==============================] - 162s 389ms/step - loss: 2.0813 - accuracy: 0.2057 - val_loss: 2.0800 - val_accuracy: 0.2111\n",
      "Epoch 27/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0769 - accuracy: 0.2249 - val_loss: 2.0738 - val_accuracy: 0.3056\n",
      "Epoch 28/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0753 - accuracy: 0.2560 - val_loss: 2.0772 - val_accuracy: 0.2167\n",
      "Epoch 29/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0786 - accuracy: 0.2081 - val_loss: 2.0835 - val_accuracy: 0.1944\n",
      "Epoch 30/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0737 - accuracy: 0.2033 - val_loss: 2.0711 - val_accuracy: 0.1722\n",
      "Epoch 31/800\n",
      "418/418 [==============================] - 162s 389ms/step - loss: 2.0697 - accuracy: 0.2871 - val_loss: 2.0722 - val_accuracy: 0.1833\n",
      "Epoch 32/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0715 - accuracy: 0.2464 - val_loss: 2.0681 - val_accuracy: 0.2889\n",
      "Epoch 33/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 2.0676 - accuracy: 0.2584 - val_loss: 2.0663 - val_accuracy: 0.1667\n",
      "Epoch 34/800\n",
      "418/418 [==============================] - 162s 389ms/step - loss: 2.0676 - accuracy: 0.2177 - val_loss: 2.0637 - val_accuracy: 0.3167\n",
      "Epoch 35/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 2.0633 - accuracy: 0.2464 - val_loss: 2.0638 - val_accuracy: 0.3000\n",
      "Epoch 36/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0658 - accuracy: 0.2344 - val_loss: 2.0601 - val_accuracy: 0.1778\n",
      "Epoch 37/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 2.0641 - accuracy: 0.2273 - val_loss: 2.0731 - val_accuracy: 0.1722\n",
      "Epoch 38/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 2.0686 - accuracy: 0.2201 - val_loss: 2.0697 - val_accuracy: 0.2111\n",
      "Epoch 39/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 2.0653 - accuracy: 0.2464 - val_loss: 2.0764 - val_accuracy: 0.1722\n",
      "Epoch 40/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 2.0677 - accuracy: 0.2201 - val_loss: 2.0602 - val_accuracy: 0.2889\n",
      "Epoch 41/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 2.0607 - accuracy: 0.2751 - val_loss: 2.0708 - val_accuracy: 0.1556\n",
      "Epoch 42/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 2.0659 - accuracy: 0.2033 - val_loss: 2.0670 - val_accuracy: 0.1778\n",
      "Epoch 43/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 2.0553 - accuracy: 0.2225 - val_loss: 2.0712 - val_accuracy: 0.1500\n",
      "Epoch 44/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 2.0573 - accuracy: 0.2105 - val_loss: 2.0568 - val_accuracy: 0.2667\n",
      "Epoch 45/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 2.0577 - accuracy: 0.2201 - val_loss: 2.0591 - val_accuracy: 0.1556\n",
      "Epoch 46/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 2.0525 - accuracy: 0.2225 - val_loss: 2.0631 - val_accuracy: 0.1556\n",
      "Epoch 47/800\n",
      "418/418 [==============================] - 162s 389ms/step - loss: 2.0523 - accuracy: 0.2153 - val_loss: 2.0568 - val_accuracy: 0.1556\n",
      "Epoch 48/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 2.0491 - accuracy: 0.2440 - val_loss: 2.0513 - val_accuracy: 0.1611\n",
      "Epoch 49/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 2.0478 - accuracy: 0.2129 - val_loss: 2.0400 - val_accuracy: 0.2944\n",
      "Epoch 50/800\n",
      "418/418 [==============================] - 162s 389ms/step - loss: 2.0442 - accuracy: 0.2967 - val_loss: 2.0392 - val_accuracy: 0.3167\n",
      "Epoch 51/800\n",
      "418/418 [==============================] - 162s 389ms/step - loss: 2.0423 - accuracy: 0.2703 - val_loss: 2.0878 - val_accuracy: 0.1389\n",
      "Epoch 52/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0555 - accuracy: 0.2536 - val_loss: 2.0351 - val_accuracy: 0.2222\n",
      "Epoch 53/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0363 - accuracy: 0.3038 - val_loss: 2.0363 - val_accuracy: 0.2944\n",
      "Epoch 54/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0328 - accuracy: 0.2775 - val_loss: 2.0814 - val_accuracy: 0.1500\n",
      "Epoch 55/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0357 - accuracy: 0.2488 - val_loss: 2.0329 - val_accuracy: 0.1722\n",
      "Epoch 56/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/418 [==============================] - 162s 389ms/step - loss: 2.0291 - accuracy: 0.2368 - val_loss: 2.0200 - val_accuracy: 0.3389\n",
      "Epoch 57/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0183 - accuracy: 0.2895 - val_loss: 2.0494 - val_accuracy: 0.1889\n",
      "Epoch 58/800\n",
      "418/418 [==============================] - 162s 389ms/step - loss: 2.0174 - accuracy: 0.2895 - val_loss: 2.0205 - val_accuracy: 0.2889\n",
      "Epoch 59/800\n",
      "418/418 [==============================] - 162s 389ms/step - loss: 2.0184 - accuracy: 0.2943 - val_loss: 2.0330 - val_accuracy: 0.1611\n",
      "Epoch 60/800\n",
      "418/418 [==============================] - 162s 389ms/step - loss: 2.0113 - accuracy: 0.2943 - val_loss: 2.0552 - val_accuracy: 0.1667\n",
      "Epoch 61/800\n",
      "418/418 [==============================] - 162s 388ms/step - loss: 2.0045 - accuracy: 0.3062 - val_loss: 2.0292 - val_accuracy: 0.2056\n",
      "Epoch 62/800\n",
      "418/418 [==============================] - 162s 389ms/step - loss: 2.0124 - accuracy: 0.3038 - val_loss: 2.0105 - val_accuracy: 0.2056\n",
      "Epoch 63/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 1.9932 - accuracy: 0.2751 - val_loss: 2.0255 - val_accuracy: 0.2222\n",
      "Epoch 64/800\n",
      "418/418 [==============================] - 162s 389ms/step - loss: 1.9931 - accuracy: 0.3134 - val_loss: 2.0159 - val_accuracy: 0.1778\n",
      "Epoch 65/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 1.9768 - accuracy: 0.2990 - val_loss: 1.9822 - val_accuracy: 0.2833\n",
      "Epoch 66/800\n",
      "418/418 [==============================] - 182s 435ms/step - loss: 1.9625 - accuracy: 0.2584 - val_loss: 1.9445 - val_accuracy: 0.3333\n",
      "Epoch 67/800\n",
      "418/418 [==============================] - 209s 499ms/step - loss: 1.9763 - accuracy: 0.2990 - val_loss: 2.0026 - val_accuracy: 0.1889\n",
      "Epoch 68/800\n",
      "418/418 [==============================] - 211s 504ms/step - loss: 1.9519 - accuracy: 0.2727 - val_loss: 2.0454 - val_accuracy: 0.1500\n",
      "Epoch 69/800\n",
      "418/418 [==============================] - 178s 427ms/step - loss: 1.9530 - accuracy: 0.2919 - val_loss: 1.9716 - val_accuracy: 0.2667\n",
      "Epoch 70/800\n",
      "418/418 [==============================] - 163s 390ms/step - loss: 1.9327 - accuracy: 0.3158 - val_loss: 2.1275 - val_accuracy: 0.1500\n",
      "Epoch 71/800\n",
      "418/418 [==============================] - 163s 390ms/step - loss: 1.9394 - accuracy: 0.2967 - val_loss: 1.9339 - val_accuracy: 0.3556\n",
      "Epoch 72/800\n",
      "418/418 [==============================] - 163s 391ms/step - loss: 1.9118 - accuracy: 0.2943 - val_loss: 1.9428 - val_accuracy: 0.2167\n",
      "Epoch 73/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.8907 - accuracy: 0.3038 - val_loss: 1.9253 - val_accuracy: 0.2111\n",
      "Epoch 74/800\n",
      "418/418 [==============================] - 164s 391ms/step - loss: 1.8839 - accuracy: 0.2775 - val_loss: 2.0306 - val_accuracy: 0.1611\n",
      "Epoch 75/800\n",
      "418/418 [==============================] - 164s 391ms/step - loss: 1.9214 - accuracy: 0.2751 - val_loss: 1.9258 - val_accuracy: 0.2222\n",
      "Epoch 76/800\n",
      "418/418 [==============================] - 164s 391ms/step - loss: 1.8799 - accuracy: 0.2847 - val_loss: 1.9785 - val_accuracy: 0.2556\n",
      "Epoch 77/800\n",
      "418/418 [==============================] - 164s 391ms/step - loss: 1.8260 - accuracy: 0.3325 - val_loss: 2.2648 - val_accuracy: 0.1500\n",
      "Epoch 78/800\n",
      "418/418 [==============================] - 164s 391ms/step - loss: 1.8645 - accuracy: 0.3325 - val_loss: 1.8391 - val_accuracy: 0.3056\n",
      "Epoch 79/800\n",
      "418/418 [==============================] - 164s 391ms/step - loss: 1.8036 - accuracy: 0.3565 - val_loss: 1.7880 - val_accuracy: 0.3000\n",
      "Epoch 80/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.7835 - accuracy: 0.3565 - val_loss: 1.7643 - val_accuracy: 0.3222\n",
      "Epoch 81/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.7814 - accuracy: 0.3493 - val_loss: 2.0633 - val_accuracy: 0.1944\n",
      "Epoch 82/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.8204 - accuracy: 0.2799 - val_loss: 1.8156 - val_accuracy: 0.3333\n",
      "Epoch 83/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.7608 - accuracy: 0.3254 - val_loss: 1.7787 - val_accuracy: 0.3222\n",
      "Epoch 84/800\n",
      "418/418 [==============================] - 164s 391ms/step - loss: 1.7384 - accuracy: 0.3421 - val_loss: 1.6936 - val_accuracy: 0.3556\n",
      "Epoch 85/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.6820 - accuracy: 0.3397 - val_loss: 1.7288 - val_accuracy: 0.3667\n",
      "Epoch 86/800\n",
      "418/418 [==============================] - 163s 391ms/step - loss: 1.7608 - accuracy: 0.3541 - val_loss: 1.8060 - val_accuracy: 0.3111\n",
      "Epoch 87/800\n",
      "418/418 [==============================] - 164s 391ms/step - loss: 1.7116 - accuracy: 0.3469 - val_loss: 1.6336 - val_accuracy: 0.3333\n",
      "Epoch 88/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.6649 - accuracy: 0.3612 - val_loss: 1.6706 - val_accuracy: 0.3111\n",
      "Epoch 89/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.6595 - accuracy: 0.3301 - val_loss: 2.0576 - val_accuracy: 0.1556\n",
      "Epoch 90/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.6990 - accuracy: 0.3349 - val_loss: 1.6595 - val_accuracy: 0.3667\n",
      "Epoch 91/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.6485 - accuracy: 0.3373 - val_loss: 1.6482 - val_accuracy: 0.3167\n",
      "Epoch 92/800\n",
      "418/418 [==============================] - 163s 391ms/step - loss: 1.6232 - accuracy: 0.3612 - val_loss: 1.7960 - val_accuracy: 0.2500\n",
      "Epoch 93/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.6231 - accuracy: 0.3206 - val_loss: 1.5963 - val_accuracy: 0.3667\n",
      "Epoch 94/800\n",
      "418/418 [==============================] - 163s 391ms/step - loss: 1.6230 - accuracy: 0.3612 - val_loss: 1.7429 - val_accuracy: 0.3278\n",
      "Epoch 95/800\n",
      "418/418 [==============================] - 164s 391ms/step - loss: 1.6731 - accuracy: 0.3589 - val_loss: 1.5913 - val_accuracy: 0.3389\n",
      "Epoch 96/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.5970 - accuracy: 0.3349 - val_loss: 1.6381 - val_accuracy: 0.3611\n",
      "Epoch 97/800\n",
      "418/418 [==============================] - 163s 390ms/step - loss: 1.6101 - accuracy: 0.3684 - val_loss: 1.6616 - val_accuracy: 0.3833\n",
      "Epoch 98/800\n",
      "418/418 [==============================] - 163s 391ms/step - loss: 1.5574 - accuracy: 0.3995 - val_loss: 1.5863 - val_accuracy: 0.3389\n",
      "Epoch 99/800\n",
      "418/418 [==============================] - 163s 390ms/step - loss: 1.5263 - accuracy: 0.4067 - val_loss: 1.5422 - val_accuracy: 0.4111\n",
      "Epoch 100/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.5237 - accuracy: 0.4187 - val_loss: 1.5120 - val_accuracy: 0.3667\n",
      "Epoch 101/800\n",
      "418/418 [==============================] - 163s 391ms/step - loss: 1.5292 - accuracy: 0.3565 - val_loss: 1.9515 - val_accuracy: 0.1556\n",
      "Epoch 102/800\n",
      "418/418 [==============================] - 163s 391ms/step - loss: 1.7461 - accuracy: 0.3254 - val_loss: 1.8106 - val_accuracy: 0.2944\n",
      "Epoch 103/800\n",
      "418/418 [==============================] - 163s 390ms/step - loss: 1.6776 - accuracy: 0.3684 - val_loss: 1.7621 - val_accuracy: 0.2389\n",
      "Epoch 104/800\n",
      "418/418 [==============================] - 163s 391ms/step - loss: 1.6208 - accuracy: 0.3756 - val_loss: 1.7738 - val_accuracy: 0.2556\n",
      "Epoch 105/800\n",
      "418/418 [==============================] - 163s 390ms/step - loss: 1.6084 - accuracy: 0.3708 - val_loss: 1.6049 - val_accuracy: 0.3444\n",
      "Epoch 106/800\n",
      "418/418 [==============================] - 163s 390ms/step - loss: 1.6321 - accuracy: 0.3493 - val_loss: 1.6406 - val_accuracy: 0.3556\n",
      "Epoch 107/800\n",
      "418/418 [==============================] - 163s 390ms/step - loss: 1.5804 - accuracy: 0.3947 - val_loss: 1.7738 - val_accuracy: 0.2833\n",
      "Epoch 108/800\n",
      "418/418 [==============================] - 163s 391ms/step - loss: 1.6039 - accuracy: 0.3732 - val_loss: 1.5927 - val_accuracy: 0.3667\n",
      "Epoch 109/800\n",
      "418/418 [==============================] - 163s 391ms/step - loss: 1.5770 - accuracy: 0.3923 - val_loss: 1.5838 - val_accuracy: 0.3722\n",
      "Epoch 110/800\n",
      "418/418 [==============================] - 163s 391ms/step - loss: 1.5555 - accuracy: 0.3660 - val_loss: 1.5968 - val_accuracy: 0.3944\n",
      "Epoch 111/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/418 [==============================] - 163s 390ms/step - loss: 1.5579 - accuracy: 0.4115 - val_loss: 1.8278 - val_accuracy: 0.2722\n",
      "Epoch 112/800\n",
      "418/418 [==============================] - 163s 390ms/step - loss: 1.5940 - accuracy: 0.3565 - val_loss: 1.9350 - val_accuracy: 0.2000\n",
      "Epoch 113/800\n",
      "418/418 [==============================] - 163s 391ms/step - loss: 1.5494 - accuracy: 0.3923 - val_loss: 1.5288 - val_accuracy: 0.3833\n",
      "Epoch 114/800\n",
      "418/418 [==============================] - 164s 391ms/step - loss: 1.5326 - accuracy: 0.4043 - val_loss: 1.5267 - val_accuracy: 0.4056\n",
      "Epoch 115/800\n",
      "418/418 [==============================] - 163s 390ms/step - loss: 1.5356 - accuracy: 0.3517 - val_loss: 1.5368 - val_accuracy: 0.3833\n",
      "Epoch 116/800\n",
      "418/418 [==============================] - 163s 389ms/step - loss: 1.5325 - accuracy: 0.3828 - val_loss: 1.5302 - val_accuracy: 0.4000\n",
      "Epoch 117/800\n",
      "418/418 [==============================] - 163s 390ms/step - loss: 1.5061 - accuracy: 0.4115 - val_loss: 2.1083 - val_accuracy: 0.1556\n",
      "Epoch 118/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.5830 - accuracy: 0.3517 - val_loss: 1.5813 - val_accuracy: 0.4167\n",
      "Epoch 119/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.5420 - accuracy: 0.4139 - val_loss: 1.5680 - val_accuracy: 0.3889\n",
      "Epoch 120/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.5599 - accuracy: 0.3900 - val_loss: 1.6139 - val_accuracy: 0.3444\n",
      "Epoch 121/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.5250 - accuracy: 0.4091 - val_loss: 1.7342 - val_accuracy: 0.2833\n",
      "Epoch 122/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.5431 - accuracy: 0.4067 - val_loss: 1.8821 - val_accuracy: 0.2111\n",
      "Epoch 123/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.5323 - accuracy: 0.3852 - val_loss: 1.6870 - val_accuracy: 0.2444\n",
      "Epoch 124/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.4960 - accuracy: 0.4211 - val_loss: 1.6312 - val_accuracy: 0.3000\n",
      "Epoch 125/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.5151 - accuracy: 0.3923 - val_loss: 1.5648 - val_accuracy: 0.3389\n",
      "Epoch 126/800\n",
      "418/418 [==============================] - 163s 391ms/step - loss: 1.4971 - accuracy: 0.4019 - val_loss: 1.8995 - val_accuracy: 0.2389\n",
      "Epoch 127/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.5386 - accuracy: 0.3971 - val_loss: 1.5055 - val_accuracy: 0.3944\n",
      "Epoch 128/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.4642 - accuracy: 0.4330 - val_loss: 1.4860 - val_accuracy: 0.3833\n",
      "Epoch 129/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.4676 - accuracy: 0.3995 - val_loss: 1.5889 - val_accuracy: 0.3778\n",
      "Epoch 130/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.4550 - accuracy: 0.4187 - val_loss: 1.5034 - val_accuracy: 0.4167\n",
      "Epoch 131/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.4573 - accuracy: 0.4450 - val_loss: 1.4850 - val_accuracy: 0.3944\n",
      "Epoch 132/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.4444 - accuracy: 0.4426 - val_loss: 1.5067 - val_accuracy: 0.3722\n",
      "Epoch 133/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.4473 - accuracy: 0.4354 - val_loss: 1.4750 - val_accuracy: 0.3722\n",
      "Epoch 134/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.4330 - accuracy: 0.4426 - val_loss: 1.4601 - val_accuracy: 0.3889\n",
      "Epoch 135/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.4287 - accuracy: 0.4163 - val_loss: 1.4779 - val_accuracy: 0.3944\n",
      "Epoch 136/800\n",
      "418/418 [==============================] - 164s 392ms/step - loss: 1.4315 - accuracy: 0.4258 - val_loss: 1.5590 - val_accuracy: 0.3611\n",
      "Epoch 137/800\n",
      "418/418 [==============================] - 164s 391ms/step - loss: 1.4827 - accuracy: 0.4139 - val_loss: 1.4973 - val_accuracy: 0.3889\n",
      "Epoch 138/800\n",
      "418/418 [==============================] - 164s 391ms/step - loss: 1.4419 - accuracy: 0.4211 - val_loss: 1.5011 - val_accuracy: 0.4000\n",
      "Epoch 139/800\n",
      "256/418 [=================>............] - ETA: 54s - loss: 1.4716 - accuracy: 0.4180"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[16,16,32,120,120] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradients/max_pooling3d_1/MaxPool3D_grad/MaxPool3DGrad (defined at c:\\users\\bipla\\anaconda3\\envs\\apptest\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_788]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-738b2cf6a18d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                   optimizer=opt, metrics=['accuracy'])\n\u001b[0;32m     10\u001b[0m     history = models[-1].fit(X_train, Y_train, validation_data=(\n\u001b[1;32m---> 11\u001b[1;33m         X_test, Y_test), batch_size=16, epochs=800, verbose=1,shuffle=True)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\bipla\\anaconda3\\envs\\apptest\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\bipla\\anaconda3\\envs\\apptest\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bipla\\anaconda3\\envs\\apptest\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bipla\\anaconda3\\envs\\apptest\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bipla\\anaconda3\\envs\\apptest\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bipla\\anaconda3\\envs\\apptest\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bipla\\anaconda3\\envs\\apptest\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\bipla\\anaconda3\\envs\\apptest\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mc:\\users\\bipla\\anaconda3\\envs\\apptest\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[16,16,32,120,120] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradients/max_pooling3d_1/MaxPool3D_grad/MaxPool3DGrad (defined at c:\\users\\bipla\\anaconda3\\envs\\apptest\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_788]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "models=[]\n",
    "nmodel = 1\n",
    "\n",
    "\n",
    "for i in range(nmodel):\n",
    "    print('model{}:'.format(i))\n",
    "    models.append(model)\n",
    "    models[-1].compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt, metrics=['accuracy'])\n",
    "    history = models[-1].fit(X_train, Y_train, validation_data=(\n",
    "        X_test, Y_test), batch_size=16, epochs=800, verbose=1,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nmodel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0af20c16ec02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nmodel' is not defined"
     ]
    }
   ],
   "source": [
    "model_inputs = [Input(shape=shape) for _ in range (nmodel)]\n",
    "model_outputs = [models[i](model_inputs[i]) for i in range (nmodel)]\n",
    "\n",
    "model = Model(inputs=model_inputs, outputs=model_outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "plot_model(model, show_shapes=True,\n",
    "      to_file=os.path.join(output, 'model.png'))\n",
    "\n",
    "model.save_weights(os.path.join(output, 'KTH_3_class_new.hd5'))\n",
    "\n",
    "loss, acc=model.evaluate([X_test]*nmodel, Y_test, verbose=0)\n",
    "with open(os.path.join(output, 'result.txt'), 'w') as f:\n",
    "    f.write('Test loss: {}\\nTest accuracy:{}'.format(loss, acc))\n",
    "\n",
    "print('merged model:')\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
